from __future__ import print_function
import numpy as np
import torch
import contextlib

import os
import sys
import errno
import numpy as np
from PIL import Image
import torch.utils.data as data
import contextlib
import pickle
from datasets.base import *
import copy
import imageio
import numpy as np
import os
from torchvision import datasets, transforms

from collections import defaultdict
from torch.utils.data import Dataset

from tqdm.autonotebook import tqdm

import PIL.Image
from PIL import Image
import pickle
import gzip
from datasets.build import DATASET_REGISTRY

__all__ = ['TinyImageNet']




@contextlib.contextmanager
def temp_seed(seed):
    state = np.random.get_state()
    np.random.seed(seed)
    try:
        yield
    finally:
        np.random.set_state(state)


def pil_loader(path):
    with open(path, 'rb') as f:
        with Image.open(f) as img:
            return img.convert('RGB')


def accimage_loader(path):
    import torchvision.datasets.accimage as accimage
    try:
        return accimage.Image(path)
    except IOError:
        return pil_loader(path)


def default_loader(path):
    from torchvision import get_image_backend
    if get_image_backend() == 'accimage':
        return accimage_loader(path)
    else:
        return pil_loader(path)


def build_set(root, split, imgs, noise_type='pairflip', noise_rate=0.5):
    """
       Function to return the lists of paths with the corresponding labels for the images
    Args:
        root (string): Root directory of dataset
        split (str): ['train', 'gallery', 'query'] returns the list pertaining to training images and labels, else otherwise
    Returns:
        return_list: list of 236_comb_fromZeroNoise-tuples with 1st location specifying path and 2nd location specifying the class
    """

    tmp_imgs = imgs

    argidx = np.argsort(tmp_imgs)




def download_and_unzip(URL, root_dir):
    error_message = "Download is not yet implemented. Please, go to {URL} urself."
    raise NotImplementedError(error_message.format(URL))

def _add_channels(img, total_channels=3):
    while len(img.shape) < 3:  # third axis is the channels
        img = np.expand_dims(img, axis=-1)
    while(img.shape[-1]) < 3:
        img = np.concatenate([img, img[:, :, -1:]], axis=-1)
    return img

class TinyImageNetPaths:
    def __init__(self, root_dir, download=False):
        if download:
            download_and_unzip('http://cs231n.stanford.edu/tiny-imagenet-200.zip',
                                root_dir)
        train_path = os.path.join(root_dir, 'train')
        val_path = os.path.join(root_dir, 'val')
        test_path = os.path.join(root_dir, 'test')

        wnids_path = os.path.join(root_dir, 'wnids.txt')
        words_path = os.path.join(root_dir, 'words.txt')

        self._make_paths(train_path, val_path, test_path,
                            wnids_path, words_path)

    def _make_paths(self, train_path, val_path, test_path,
                  wnids_path, words_path):
        self.ids = []
        with open(wnids_path, 'r') as idf:
            for nid in idf:
                nid = nid.strip()
                self.ids.append(nid)
        self.nid_to_words = defaultdict(list)
        with open(words_path, 'r') as wf:
            for line in wf:
                nid, labels = line.split('\t')
                labels = list(map(lambda x: x.strip(), labels.split(',')))
                self.nid_to_words[nid].extend(labels)

        self.paths = {'train': [],  # [img_path, id, nid, box]
                        'val': [],  # [img_path, id, nid, box]
                        'test': []  # img_path
                        }

        # Get the test paths
        self.paths['test'] = list(map(lambda x: os.path.join(test_path, x),
                                      os.listdir(test_path)))
        # Get the validation paths and labels
        with open(os.path.join(val_path, 'val_annotations.txt')) as valf:
            for line in valf:
                fname, nid, x0, y0, x1, y1 = line.split()
                fname = os.path.join(val_path, 'images', fname)
                bbox = int(x0), int(y0), int(x1), int(y1)
                label_id = self.ids.index(nid)
                self.paths['val'].append((fname, label_id, nid, bbox))

        # Get the training paths
        train_nids = os.listdir(train_path)
        for nid in train_nids:
            anno_path = os.path.join(train_path, nid, nid+'_boxes.txt')
            imgs_path = os.path.join(train_path, nid, 'images')
            label_id = self.ids.index(nid)
            with open(anno_path, 'r') as annof:
                for line in annof:
                    fname, x0, y0, x1, y1 = line.split()
                    fname = os.path.join(imgs_path, fname)
                    bbox = int(x0), int(y0), int(x1), int(y1)
                    self.paths['train'].append((fname, label_id, nid, bbox))


@DATASET_REGISTRY.register()
class TinyImageNet(data.Dataset):
    def __init__(self, root, train=True, preload=False, load_transform=None,
                transform=None, download=False, max_samples=None):
        root = os.path.join(root, 'tiny_imagenet')
        tinp = TinyImageNetPaths(root, download)
        if train:
            self.split = 'train'
        else:
            self.split = 'test'
            
        self.label_idx = 1  # from [image, id, nid, box]
        self.preload = preload
        self.transform = transform
        self.transform_results = dict()
        self.loader = default_loader

        self.IMAGE_SHAPE = (64, 64, 3)

        self.img_data = []
        self.label_data = []

        self.max_samples = max_samples
        if self.split == 'test':
            self.samples = tinp.paths['val']
        else:
            self.samples = tinp.paths['train']

        self.samples_num = len(self.samples)

        if self.max_samples is not None:
            self.samples_num = min(self.max_samples, self.samples_num)
            self.samples = np.random.permutation(self.samples)[:self.samples_num]

        if self.preload:

            file_name_img = root + "/" + self.split + "_img.pickle"
            file_name_label = root + "/" + self.split + "_label.pickle"
            try:
                #compressed
                with gzip.open(file_name_img, 'rb') as f:
                    self.img_data = pickle.load(f)
                with gzip.open(file_name_label, 'rb') as f:
                    self.label_data = pickle.load(f)

                print("Successfully load the existed img_data file")

                # with open(file_name_img, 'rb') as f:
                #     self.img_data = pickle.load(f)
                # with open(file_name_label, 'rb') as f:
                #     self.label_data = pickle.load(f)
                
            except:
                print("Cannot load the existed img_data file.. create new one")
                load_desc = "Preloading {} data...".format(split)
                self.img_data = np.zeros((self.samples_num,) + self.IMAGE_SHAPE,
                                dtype=np.float32)
                self.label_data = np.zeros((self.samples_num,), dtype=np.int)
                for idx in tqdm(range(self.samples_num), desc=load_desc):
                    s = self.samples[idx]
                    img = imageio.imread(s[0])
                    img = _add_channels(img)
                    self.img_data[idx] = img
                    if split != 'test':
                        self.label_data[idx] = s[self.label_idx]

                if load_transform:
                    for lt in load_transform:
                        result = lt(self.img_data, self.label_data)
                        self.img_data, self.label_data = result[:2]
                        if len(result) > 2:
                            self.transform_results.update(result[2])
                # with open(file_name_img, 'wb') as f:
                #     pickle.dump(self.img_data, f, pickle.HIGHEST_PROTOCOL)
                # with open(file_name_label, 'wb') as f:
                #     pickle.dump(self.label_data, f, pickle.HIGHEST_PROTOCOL)

                #Compress
                with gzip.open(file_name_img, 'wb') as f:
                    pickle.dump(self.img_data, f, pickle.HIGHEST_PROTOCOL)
                with gzip.open(file_name_label, 'wb') as f:
                    pickle.dump(self.label_data, f, pickle.HIGHEST_PROTOCOL)


                with gzip.open(file_name_img, 'rb') as f:
                    temp_img_data = pickle.load(f)
                #validate
                with gzip.open(file_name_label, 'rb') as f:
                    temp_label_data = pickle.load(f)

                assert((temp_img_data == self.img_data).mean() == 1)
                assert((temp_label_data == self.label_data).mean() == 1)

            self.data = self.img_data
            self.targets = self.label_data
            self.classes = set(self.targets)
            self.class_to_idx = {_class: i for i, _class in enumerate(self.classes)}
            #breakpoint()
        else:
            self.data = np.array([i[0] for i in self.samples])
            self.targets = np.array([i[1] for i in self.samples])
            self.classes = set(self.targets)
            self.class_to_idx = {_class: i for i, _class in enumerate(self.classes)}



    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        if self.preload:
            #img = self.img_data[idx]
            #lbl = None if self.split == 'test' else self.label_data[idx]
            img, target = self.data[idx], self.targets[idx]
            #print(type(img))
            #print(img.shape)
            #img = np.transpose(img, (2,0,1))
            #img = (torch.tensor(img))
            img = Image.fromarray((img * 255).astype(np.uint8))
            #print(type(img))
            
        else:
            img, target = self.data[idx], self.targets[idx]
            #img = imageio.imread(img)
            img = self.loader(img)
            #print(np.array(img).shape)
            #print(type(np.array(img)))
        #print(img.shape)
        
        if self.transform is not None:
            img = self.transform(img)
        return img, target


def tiny_iid(dataset, num_users):
    """
    Sample I.I.D. client data from CIFAR10 dataset
    :param dataset:
    :param num_users:
    :return: dict of image index
    """
    num_items = int(len(dataset)/num_users)
    #num_items=8
    dict_users, all_idxs = {}, [i for i in range(len(dataset))]
    for i in range(num_users):
        dict_users[i] = set(np.random.choice(all_idxs, num_items, replace=False))
        all_idxs = list(set(all_idxs) - dict_users[i])
    return dict_users


def tiny_noniid(dataset, num_users):
    """
    Sample non-I.I.D client data from CIFAR10 dataset
    :param dataset:
    :param num_users:
    :return:
    """
    # num_shards, num_imgs = 200, 250
    # num_shards, num_imgs = 200, 250
    class_per_user = 1
    num_shards = num_users * class_per_user
    num_imgs = int(len(dataset) / num_shards)
    idx_shard = [i for i in range(num_shards)]
    dict_users = {i: np.array([], dtype='int64') for i in range(num_users)}
    idxs = np.arange(num_shards * num_imgs)
    # labels = dataset.train_labels.numpy()
    # labels = np.array(dataset.train_labels)

    labels = []
    for element in dataset:
        labels.append(int(element[1]))
    # print(type(labels[0]))
    labels = np.array(labels)
    # labels=labels.astype('int64')
    # sort labels

    idxs_labels = np.vstack((idxs, labels))
    idxs_labels = idxs_labels[:, idxs_labels[1, :].argsort()]
    idxs = idxs_labels[0, :]

    # divide and assign
    for i in range(num_users):
        rand_set = set(np.random.choice(idx_shard, class_per_user, replace=False))
        idx_shard = list(set(idx_shard) - rand_set)
        for rand in rand_set:
            dict_users[i] = set(np.concatenate(
                (dict_users[i], idxs[rand * num_imgs:(rand + 1) * num_imgs]), axis=0))
    return dict_users



def tiny_dirichlet_unbalanced(dataset, n_nets, alpha=0.5):
    '''
    if dataset == 'mnist':
        X_train, y_train, X_test, y_test = load_mnist_data(datadir)
    elif dataset == 'cifar10':
        X_train, y_train, X_test, y_test = load_cifar10_data(datadir)
    '''
    #X_train=dataset[:][0]
    y_train=torch.zeros(len(dataset),dtype=torch.long)
    print(y_train.dtype)
    for a in range(len(dataset)):
        y_train[a]=(dataset[a][1])
    n_train = len(dataset)
    #X_train.shape[0]
    '''
    if partition == "homo":
        idxs = np.random.permutation(n_train)
        batch_idxs = np.array_split(idxs, n_nets)
        net_dataidx_map = {i: batch_idxs[i] for i in range(n_nets)}
    '''
    #elif partition == "hetero-dir":
    min_size = 0
    K = len(dataset.class_to_idx)
    N=len(dataset)
    N = y_train.shape[0]
    net_dataidx_map = {i: np.array([],dtype='int64') for i in range(n_nets)}

    while min_size < 10:
        idx_batch = [[] for _ in range(n_nets)]
        for k in range(K):
            idx_k = np.where(y_train == k)[0]
            np.random.shuffle(idx_k)
            proportions = np.random.dirichlet(np.repeat(alpha, n_nets))
            ## Balance
            proportions = np.array([p*(len(idx_j)<N/n_nets) for p,idx_j in zip(proportions,idx_batch)])
            proportions = proportions/proportions.sum()
            proportions = (np.cumsum(proportions)*len(idx_k)).astype(int)[:-1]
            idx_batch = [idx_j + idx.tolist() for idx_j,idx in zip(idx_batch,np.split(idx_k,proportions))]
            min_size = min([len(idx_j) for idx_j in idx_batch])

        for j in range(n_nets):
            np.random.shuffle(idx_batch[j])
            net_dataidx_map[j] = idx_batch[j]

    #traindata_cls_counts = record_net_data_stats(y_train, net_dataidx_map, logdir)
    return net_dataidx_map
    #return (X_train, y_train, X_test, y_test, net_dataidx_map, traindata_cls_counts)

def tiny_dirichlet_balanced(dataset, n_nets, alpha=0.5):
    with temp_seed(0):
        y_train=torch.zeros(len(dataset),dtype=torch.long)

        for a in range(len(dataset)):
            y_train[a]=(dataset[a][1])
        n_train = len(dataset)

        min_size = 0
        K = len(dataset.class_to_idx)
        N = len(dataset)
        N = y_train.shape[0]
        print(N)
        net_dataidx_map = {i: np.array([], dtype='int64') for i in range(n_nets)}
        assigned_ids = []
        idx_batch = [[] for _ in range(n_nets)]
        num_data_per_client=int(N/n_nets)
        for i in range(n_nets):
            weights = torch.zeros(N)
            proportions = np.random.dirichlet(np.repeat(alpha, K))
            for k in range(K):
                idx_k = np.where(y_train == k)[0]
                weights[idx_k]=proportions[k]
            weights[assigned_ids] = 0.0
            idx_batch[i] = (torch.multinomial(weights, num_data_per_client, replacement=False)).tolist()
            assigned_ids+=idx_batch[i]

        for j in range(n_nets):
            np.random.shuffle(idx_batch[j])
            net_dataidx_map[j] = idx_batch[j]

    #traindata_cls_counts = record_net_data_stats(y_train, net_dataidx_map, logdir)
    return net_dataidx_map
    #return (X_train, y_train, X_test, y_test, net_dataidx_map, traindata_cls_counts)


if __name__ == '__main__':
    transform = transforms.Compose([
        transforms.Resize(64),
        transforms.CenterCrop(64),
        # resize 256_comb_coteach_OpenNN_CIFAR -> random_crop 224 ==> crop 32, padding 4
        transforms.ToTensor()
    ])

    exs = TinyImageNetDataset('../data/tiny_imagenet', split='train', transform=transform)


    mean = 0
    sq_mean = 0
    for ex in exs:
        mean += ex[0].sum(1).sum(1) / (64 * 64)
        sq_mean += ex[0].pow(2).sum(1).sum(1) / (64 * 64)

    mean /= len(exs)
    sq_mean /= len(exs)

    std = (sq_mean - mean.pow(2)).pow(0.5)

    print(mean)
    print(std)